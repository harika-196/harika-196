echo "# tic-tac-toe" >> README.md
git init
git add README.md
git commit -m "first commit"
git branch -M main
git remote add origin https://github.com/harika-196/tic-tac-toe.git
git push -u origin main
import cv2
import face_recognition

# Load the pre-trained face detection model (Haar cascades)
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Load the pre-trained face recognition model (HOG-based)
hog_face_detector = dlib.get_frontal_face_detector()

# Load a pre-trained face recognition model (optional)
# This model is used for feature extraction and comparison
# You may need to install face_recognition_models by running: pip install face_recognition_models
face_recognition_model = face_recognition.load_model_location("face_recognition_models")

# Load known faces and their corresponding names
known_faces = []
known_names = []

# Example: Load known faces and names from a folder
# Each image in the folder should contain a single face with a clear view
# Naming convention: "person_name.jpg"
known_faces_folder = "known_faces"
for file_name in os.listdir(known_faces_folder):
    image_path = os.path.join(known_faces_folder, file_name)
    image = face_recognition.load_image_file(image_path)
    face_encoding = face_recognition.face_encodings(image)[0]
    known_faces.append(face_encoding)
    known_names.append(os.path.splitext(file_name)[0])

# Open a video capture object (you can replace '0' with your video file name)
cap = cv2.VideoCapture(0)

while True:
    # Read a frame from the video capture
    ret, frame = cap.read()

    # Convert the frame to grayscale for Haar cascades face detection
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Perform face detection using Haar cascades
    faces_haar = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)

    # Perform face detection using HOG-based face detector
    faces_hog = hog_face_detector(frame)

    # Draw rectangles around the detected faces
    for (x, y, w, h) in faces_haar:
        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)

    for face in faces_hog:
        (x, y, w, h) = (face.left(), face.top(), face.width(), face.height())
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)

        # Optional: Perform face recognition using the loaded known faces
        face_encoding = face_recognition.face_encodings(frame, [(y, x+w, y+h, x)])[0]
        matches = face_recognition.compare_faces(known_faces, face_encoding)

        name = "Unknown"
        if True in matches:
            first_match_index = matches.index(True)
            name = known_names[first_match_index]

        cv2.putText(frame, name, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    # Display the resulting frame
    cv2.imshow('Face Detection and Recognition', frame)

    # Break the loop if 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture object and close all windows
cap.release()
cv2.destroyAllWindows()
